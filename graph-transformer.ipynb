{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch_geometric.transforms as T\n",
    "from torch import lgamma\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_mean\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import ogb\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of relative positional encodings for graph Transformers')\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 7\n",
    "args.device = torch.device('cuda:'+ str(args.device) if torch.cuda.is_available() else 'cpu')\n",
    "# args.device = torch.device('cpu')\n",
    "print(\"device:\", args.device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class GraphTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout=True):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(layers):\n",
    "            self.layers.append(GraphTransformerLayer(embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout))\n",
    "    \n",
    "    def forward(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x, _ = layer(x, relation, kv, self_padding_mask, self_attn_mask)\n",
    "        return x\n",
    "\n",
    "    def get_attn_weights(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None):\n",
    "        attns = []\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x, attn = layer(x, relation, kv, self_padding_mask, self_attn_mask, need_weights=True)\n",
    "            attns.append(attn)\n",
    "        attn = torch.stack(attns)\n",
    "        return attn\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout=True):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = RelationMultiheadAttention(embed_dim, num_heads, dropout, weights_dropout)\n",
    "        self.fc1 = nn.Linear(embed_dim, ff_embed_dim)\n",
    "        self.fc2 = nn.Linear(ff_embed_dim, embed_dim)\n",
    "        self.attn_layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = dropout\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.fc1.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc2.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0.)\n",
    "        nn.init.constant_(self.fc2.bias, 0.)\n",
    "\n",
    "    def forward(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None,\n",
    "                need_weights = False):\n",
    "        # x: seq_len x bsz x embed_dim\n",
    "        residual = x\n",
    "        if kv is None:\n",
    "            x, self_attn = self.self_attn(query=x, key=x, value=x, relation=relation, key_padding_mask=self_padding_mask, attn_mask=self_attn_mask, need_weights=need_weights)\n",
    "        else:\n",
    "            x, self_attn = self.self_attn(query=x, key=kv, value=kv, relation=relation, key_padding_mask=self_padding_mask, attn_mask=self_attn_mask, need_weights=need_weights)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.attn_layer_norm(residual + x)\n",
    "\n",
    "        residual = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.ff_layer_norm(residual + x)\n",
    "        return x, self_attn\n",
    "\n",
    "class RelationMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., weights_dropout=True):\n",
    "        super(RelationMultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "\n",
    "        self.in_proj_weight = Parameter(torch.Tensor(3 * embed_dim, embed_dim))\n",
    "        self.in_proj_bias = Parameter(torch.Tensor(3 * embed_dim))\n",
    "        self.relation_in_proj = nn.Linear(embed_dim, 2*embed_dim, bias=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=True)\n",
    "        self.weights_dropout = weights_dropout\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.in_proj_weight, std=0.02)\n",
    "        nn.init.normal_(self.out_proj.weight, std=0.02)\n",
    "        nn.init.normal_(self.relation_in_proj.weight, std=0.02)\n",
    "        nn.init.constant_(self.in_proj_bias, 0.)\n",
    "        nn.init.constant_(self.out_proj.bias, 0.)\n",
    "\n",
    "    def forward(self, query, key, value, relation, key_padding_mask=None, attn_mask=None, need_weights=False):\n",
    "        \"\"\" Input shape: Time x Batch x Channel\n",
    "            relation:  tgt_len x src_len x bsz x dim\n",
    "            key_padding_mask: Time x batch\n",
    "            attn_mask:  tgt_len x src_len\n",
    "        \"\"\"\n",
    "        qkv_same = query.data_ptr() == key.data_ptr() == value.data_ptr()\n",
    "        kv_same = key.data_ptr() == value.data_ptr()\n",
    "\n",
    "        tgt_len, bsz, embed_dim = query.size()\n",
    "        src_len = key.size(0)\n",
    "        assert key.size() == value.size()\n",
    "\n",
    "        if qkv_same:\n",
    "            # self-attention\n",
    "            q, k, v = self.in_proj_qkv(query)\n",
    "        elif kv_same:\n",
    "            # encoder-decoder attention\n",
    "            q = self.in_proj_q(query)\n",
    "            k, v = self.in_proj_kv(key)\n",
    "        else:\n",
    "            q = self.in_proj_q(query)\n",
    "            k = self.in_proj_k(key)\n",
    "            v = self.in_proj_v(value)\n",
    "\n",
    "        q = q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim)\n",
    "        k = k.contiguous().view(src_len, bsz * self.num_heads, self.head_dim)\n",
    "        v = v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim)\n",
    "\n",
    "        ra, rb = self.relation_in_proj(relation).chunk(2, dim=-1)\n",
    "        ra = ra.contiguous().view(tgt_len, src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n",
    "        rb = rb.contiguous().view(tgt_len, src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n",
    "\n",
    "        q = q.unsqueeze(1) + ra\n",
    "        k = k.unsqueeze(0) + rb\n",
    "        q *= self.scaling\n",
    "        # q: tgt_len x src_len x bsz*heads x dim\n",
    "        # k: tgt_len x src_len x bsz*heads x dim\n",
    "        # v: src_len x bsz*heads x dim\n",
    "\n",
    "        attn_weights = torch.einsum('ijbn,ijbn->ijb', [q, k])\n",
    "        assert list(attn_weights.size()) == [tgt_len, src_len, bsz * self.num_heads]\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_weights.masked_fill_(\n",
    "                attn_mask.unsqueeze(-1),\n",
    "                float('-inf')\n",
    "            )\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            # don't attend to padding symbols\n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz, self.num_heads)\n",
    "            attn_weights.masked_fill_(\n",
    "                key_padding_mask.unsqueeze(0).unsqueeze(-1),\n",
    "                float('-inf')\n",
    "            )\n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz * self.num_heads)\n",
    "\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)\n",
    "\n",
    "        if self.weights_dropout:\n",
    "            attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        # attn_weights: tgt_len x src_len x bsz*heads\n",
    "        # v: src_len x bsz*heads x dim\n",
    "        attn = torch.einsum('ijb,jbn->bin', [attn_weights, v])\n",
    "        if not self.weights_dropout:\n",
    "            attn = F.dropout(attn, p=self.dropout, training=self.training)\n",
    "\n",
    "        assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
    "\n",
    "        attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
    "        attn = self.out_proj(attn)\n",
    "\n",
    "        if need_weights:\n",
    "            # maximum attention weight over heads \n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz, self.num_heads)\n",
    "        else:\n",
    "            attn_weights = None\n",
    "\n",
    "        return attn, attn_weights\n",
    "\n",
    "    def in_proj_qkv(self, query):\n",
    "        return self._in_proj(query).chunk(3, dim=-1)\n",
    "\n",
    "    def in_proj_kv(self, key):\n",
    "        return self._in_proj(key, start=self.embed_dim).chunk(2, dim=-1)\n",
    "\n",
    "    def in_proj_q(self, query):\n",
    "        return self._in_proj(query, end=self.embed_dim)\n",
    "\n",
    "    def in_proj_k(self, key):\n",
    "        return self._in_proj(key, start=self.embed_dim, end=2 * self.embed_dim)\n",
    "\n",
    "    def in_proj_v(self, value):\n",
    "        return self._in_proj(value, start=2 * self.embed_dim)\n",
    "\n",
    "    def _in_proj(self, input, start=0, end=None):\n",
    "        weight = self.in_proj_weight\n",
    "        bias = self.in_proj_bias\n",
    "        weight = weight[start:end, :]\n",
    "        if bias is not None:\n",
    "            bias = bias[start:end]\n",
    "        return F.linear(input, weight, bias)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'ogbg-moltox21'\n",
    "args.n_classes = 12\n",
    "# args.batch_size = 66666\n",
    "args.batch_size = 32\n",
    "args.lr = 0.001\n",
    "args.graph_pooling = 'mean'\n",
    "args.proj_mode = 'nonlinear'\n",
    "args.eval_metric = 'rocauc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "class GraphTransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, nclasses, layers, embed_dim, ff_embed_dim, num_heads, dropout, relation_type='link', max_vocab=2, weights_dropout=True):\n",
    "        super(GraphTransformerModel, self).__init__()\n",
    "        self.model_type = 'GraphTransformerModel'\n",
    "        self.encoder = AtomEncoder(emb_dim=embed_dim)\n",
    "        self.transformer = GraphTransformer(layers, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout)\n",
    "        \n",
    "        #Different kind of graph pooling\n",
    "        if args.graph_pooling == \"sum\":\n",
    "            self.graph_pool = global_add_pool\n",
    "        elif args.graph_pooling == \"mean\":\n",
    "            self.graph_pool = global_mean_pool\n",
    "        elif args.graph_pooling == \"max\":\n",
    "            self.graph_pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "        \n",
    "        self.task_pred = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, nclasses)\n",
    "        )\n",
    "        \n",
    "        self.relation_type = relation_type\n",
    "        self.max_vocab = max_vocab\n",
    "        self.relation_encoder = nn.Embedding(max_vocab, embed_dim)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        x, mask = to_dense_batch(self.encoder(src.x), batch=src.batch, fill_value=0)\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        if self.relation_type == 'link':\n",
    "            relation = self.relation_encoder(to_dense_adj(src.edge_index, batch=src.batch, max_num_nodes=x.size(0)).long())\n",
    "        elif self.relation_type == 'shortest_dist':\n",
    "            mod_sd_edge_attr = torch.clamp(src.sd_edge_attr.reshape(-1), 0, self.max_vocab - 1).long()\n",
    "            relation = self.relation_encoder(to_dense_adj(src.sd_edge_index, batch=src.batch, edge_attr=mod_sd_edge_attr, max_num_nodes=x.size(0)).long())\n",
    "        else:\n",
    "            raise ValueError(\"Invalid relation type.\")\n",
    "        \n",
    "        relation = relation.permute(2, 1, 0, 3)\n",
    "        \n",
    "        output = self.transformer(x, relation, self_padding_mask=~mask.transpose(0, 1))\n",
    "        \n",
    "        graph_emb = self.graph_pool(output.transpose(0, 1)[mask], src.batch)\n",
    "        graph_pred = self.task_pred(graph_emb)\n",
    "        \n",
    "        return graph_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.shortest_paths.generic import shortest_path \n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def compute_mutual_shortest_distances(d):\n",
    "    d_nx = to_networkx(d, to_undirected=True)\n",
    "    p = shortest_path(d_nx)\n",
    "    \n",
    "    sd_edge_index = torch.LongTensor(2, d.x.size(0) * d.x.size(0))\n",
    "    sd_edge_attr = torch.FloatTensor(d.x.size(0) * d.x.size(0), 1)\n",
    "    for i in range(d.x.size(0)):\n",
    "        for j in range(d.x.size(0)):\n",
    "            sd_edge_index[0][i * d.x.size(0) + j] = i\n",
    "            sd_edge_index[1][i * d.x.size(0) + j] = j\n",
    "            \n",
    "            if j in p[i]:\n",
    "                sd_edge_attr[i * d.x.size(0) + j] = len(p[i][j]) - 1\n",
    "            else:\n",
    "                sd_edge_attr[i * d.x.size(0) + j] = float(\"inf\")\n",
    "        \n",
    "    return Data(x=d.x, y=d.y, edge_index=d.edge_index, edge_attr=d.edge_attr, sd_edge_index=sd_edge_index, sd_edge_attr=sd_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "dataset: ogbg-moltox21 \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "print(\"dataset: {} \".format(args.dataset))\n",
    "dataset = PygGraphPropPredDataset(name=args.dataset, pre_transform=compute_mutual_shortest_distances).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(dataset[0].sd_edge_attr, 0, 12).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.28731900652249653\n",
      "Test loss: 0.219830932871749\n",
      "Test ROC-AUC: 0.7682430363286356\n",
      "Train loss: 0.22710513048447095\n",
      "Test loss: 0.20683357181648412\n",
      "Test ROC-AUC: 0.7931925162784316\n",
      "Train loss: 0.21777354326003637\n",
      "Test loss: 0.21242784584561983\n",
      "Test ROC-AUC: 0.8041157865393856\n",
      "Train loss: 0.21209122985601425\n",
      "Test loss: 0.2152405809611082\n",
      "Test ROC-AUC: 0.8013292636370032\n",
      "Train loss: 0.20804992696413627\n",
      "Test loss: 0.20278794954841337\n",
      "Test ROC-AUC: 0.8074740230994637\n",
      "Train loss: 0.2032576819642996\n",
      "Test loss: 0.1949675747503837\n",
      "Test ROC-AUC: 0.8196930141400599\n",
      "Train loss: 0.19902694828999348\n",
      "Test loss: 0.2069052898635467\n",
      "Test ROC-AUC: 0.8067255358201423\n",
      "Train loss: 0.19625839843199802\n",
      "Test loss: 0.19877151135976115\n",
      "Test ROC-AUC: 0.8213787502281819\n",
      "Train loss: 0.19493871541359487\n",
      "Test loss: 0.20582046980659166\n",
      "Test ROC-AUC: 0.8114081489274927\n",
      "Train loss: 0.18996064047782849\n",
      "Test loss: 0.2110206556196014\n",
      "Test ROC-AUC: 0.8255422539853746\n",
      "Train loss: 0.18735077415521328\n",
      "Test loss: 0.22480685791621605\n",
      "Test ROC-AUC: 0.8127511793093308\n",
      "Train loss: 0.1877223096214808\n",
      "Test loss: 0.21805804797137776\n",
      "Test ROC-AUC: 0.8195847859972686\n",
      "Train loss: 0.18477686891953152\n",
      "Test loss: 0.2053790233718852\n",
      "Test ROC-AUC: 0.8258365615832495\n",
      "Train loss: 0.18205887098342943\n",
      "Test loss: 0.2054138251890739\n",
      "Test ROC-AUC: 0.8295932987240451\n",
      "Train loss: 0.18043469068331597\n",
      "Test loss: 0.21446716242159405\n",
      "Test ROC-AUC: 0.826928440250733\n",
      "Train loss: 0.17974501443214905\n",
      "Test loss: 0.20081751871233186\n",
      "Test ROC-AUC: 0.8342704210371913\n",
      "Train loss: 0.18006177089917355\n",
      "Test loss: 0.2001039149860541\n",
      "Test ROC-AUC: 0.8269494898633418\n",
      "Train loss: 0.17636103309117832\n",
      "Test loss: 0.2004557903856039\n",
      "Test ROC-AUC: 0.830661947799333\n",
      "Train loss: 0.1759931484858195\n",
      "Test loss: 0.19046459921325246\n",
      "Test ROC-AUC: 0.8372887761075835\n",
      "Train loss: 0.1731282317485565\n",
      "Test loss: 0.20952187292277813\n",
      "Test ROC-AUC: 0.8309933039501654\n",
      "Train loss: 0.17209291805823643\n",
      "Test loss: 0.195477158917735\n",
      "Test ROC-AUC: 0.830363973885392\n",
      "Train loss: 0.17276241038090143\n",
      "Test loss: 0.19317588986208042\n",
      "Test ROC-AUC: 0.8327072248764821\n",
      "Train loss: 0.17090384448185944\n",
      "Test loss: 0.19846495737632117\n",
      "Test ROC-AUC: 0.8244202355181534\n",
      "Train loss: 0.17063069221300955\n",
      "Test loss: 0.1994981300085783\n",
      "Test ROC-AUC: 0.8279626065825801\n",
      "Train loss: 0.17070140154697958\n",
      "Test loss: 0.19086266697073975\n",
      "Test ROC-AUC: 0.834958986841753\n",
      "Train loss: 0.16809581021467845\n",
      "Test loss: 0.19691354998697838\n",
      "Test ROC-AUC: 0.8347778807173029\n",
      "Train loss: 0.16749440660843481\n",
      "Test loss: 0.1936832444431881\n",
      "Test ROC-AUC: 0.8330420186668702\n",
      "Train loss: 0.16541896588527238\n",
      "Test loss: 0.2087664919284483\n",
      "Test ROC-AUC: 0.8253202818399276\n",
      "Train loss: 0.16395927468935648\n",
      "Test loss: 0.20375188160687685\n",
      "Test ROC-AUC: 0.8327286301038465\n",
      "Train loss: 0.16292309080943082\n",
      "Test loss: 0.19346713817988834\n",
      "Test ROC-AUC: 0.8334245746556171\n",
      "Train loss: 0.1625142387090585\n",
      "Test loss: 0.2027348579528431\n",
      "Test ROC-AUC: 0.8414377581275633\n",
      "Train loss: 0.16037812741138996\n",
      "Test loss: 0.1973099495905141\n",
      "Test ROC-AUC: 0.8333903368304875\n",
      "Train loss: 0.16126572241385778\n",
      "Test loss: 0.20318124381204447\n",
      "Test ROC-AUC: 0.8282741823384742\n",
      "Train loss: 0.15958529684023978\n",
      "Test loss: 0.20578456732134023\n",
      "Test ROC-AUC: 0.8263502698442943\n",
      "Train loss: 0.15991079673553124\n",
      "Test loss: 0.2009798848691086\n",
      "Test ROC-AUC: 0.827877473687796\n",
      "Train loss: 0.15759550141982542\n",
      "Test loss: 0.20157093290860453\n",
      "Test ROC-AUC: 0.8280722103372583\n",
      "Train loss: 0.15739646531068363\n",
      "Test loss: 0.20615762984380126\n",
      "Test ROC-AUC: 0.8307023079856547\n",
      "Train loss: 0.15677107140803948\n",
      "Test loss: 0.20502865919843316\n",
      "Test ROC-AUC: 0.832961399660154\n",
      "Train loss: 0.1535259296114628\n",
      "Test loss: 0.20872525358572602\n",
      "Test ROC-AUC: 0.8278465880024272\n",
      "Train loss: 0.15318129020623672\n",
      "Test loss: 0.2056534035752217\n",
      "Test ROC-AUC: 0.8258490447651372\n",
      "Train loss: 0.1537098594200917\n",
      "Test loss: 0.20363709734131893\n",
      "Test ROC-AUC: 0.8275780669262832\n",
      "Train loss: 0.15590472542322598\n",
      "Test loss: 0.2094270346375803\n",
      "Test ROC-AUC: 0.8255592793680958\n",
      "Train loss: 0.15167989746118204\n",
      "Test loss: 0.19996832932035127\n",
      "Test ROC-AUC: 0.8333379796669714\n",
      "Train loss: 0.1514619923554934\n",
      "Test loss: 0.21582970302551985\n",
      "Test ROC-AUC: 0.8182103935469858\n",
      "Train loss: 0.15703816750110725\n",
      "Test loss: 0.2026681488690277\n",
      "Test ROC-AUC: 0.8305336685986696\n",
      "Train loss: 0.15636982100132185\n",
      "Test loss: 0.19696548953652382\n",
      "Test ROC-AUC: 0.8382103303447038\n",
      "Train loss: 0.15376200538415175\n",
      "Test loss: 0.1949362438172102\n",
      "Test ROC-AUC: 0.834990937088261\n",
      "Train loss: 0.15046216249465943\n",
      "Test loss: 0.20001814172913632\n",
      "Test ROC-AUC: 0.8371585865680715\n",
      "Train loss: 0.1510760941184484\n",
      "Test loss: 0.19874545528242984\n",
      "Test ROC-AUC: 0.8323179939237986\n",
      "Train loss: 0.15158488674041554\n",
      "Test loss: 0.20036801494037113\n",
      "Test ROC-AUC: 0.8324243414229883\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset[:int(0.8 * len(dataset))], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(dataset[int(0.8 * len(dataset)):], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# embed_dim = 512\n",
    "embed_dim = 128\n",
    "# ff_embed_dim = 1024\n",
    "ff_embed_dim = 256\n",
    "num_heads = 8\n",
    "# graph_layers = 4\n",
    "graph_layers = 2\n",
    "dropout = 0.2\n",
    "relation_type = 'shortest_dist'\n",
    "max_vocab = 12\n",
    "model = GraphTransformerModel(args.n_classes, graph_layers, embed_dim, ff_embed_dim, num_heads, dropout, relation_type, max_vocab).to(args.device)\n",
    "\n",
    "# To train Transformer, better to use the default hyperparameter for optimizer and LR scheduler.\n",
    "# You can refer to some latest code as a reference.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "evaluator = Evaluator(name=args.dataset)\n",
    "\n",
    "args.num_epochs = 50\n",
    "for epoch in range(args.num_epochs):\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_epoch = 0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        z = model(batch.to(args.device))\n",
    "\n",
    "        y = batch.y.float()\n",
    "        is_valid = ~torch.isnan(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(z[is_valid], y[is_valid])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    print('Train loss:', loss_epoch / len(train_loader))\n",
    "    \n",
    "    ##############\n",
    "    # EVALUATION #\n",
    "    ##############\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_epoch = 0\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            z = model(batch.to(args.device))\n",
    "\n",
    "            y = batch.y.float()\n",
    "            y_true.append(y)\n",
    "            y_scores.append(z)\n",
    "            is_valid = ~torch.isnan(y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(z[is_valid], y[is_valid])\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim = 0)\n",
    "        y_scores = torch.cat(y_scores, dim = 0)\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_scores}\n",
    "    result_dict = evaluator.eval(input_dict)\n",
    "    print('Test loss:', loss_epoch / len(test_loader))\n",
    "    print('Test ROC-AUC:', result_dict[args.eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual shortest path between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison to SOTA (copy from GIN notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
