{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch_geometric.transforms as T\n",
    "from torch import lgamma\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_mean\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import ogb\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of relative positional encodings for graph Transformers')\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 7\n",
    "args.device = torch.device('cuda:'+ str(args.device) if torch.cuda.is_available() else 'cpu')\n",
    "# args.device = torch.device('cpu')\n",
    "print(\"device:\", args.device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class GraphTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout=True):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(layers):\n",
    "            self.layers.append(GraphTransformerLayer(embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout))\n",
    "    \n",
    "    def forward(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None):\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x, _ = layer(x, relation, kv, self_padding_mask, self_attn_mask)\n",
    "        return x\n",
    "\n",
    "    def get_attn_weights(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None):\n",
    "        attns = []\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x, attn = layer(x, relation, kv, self_padding_mask, self_attn_mask, need_weights=True)\n",
    "            attns.append(attn)\n",
    "        attn = torch.stack(attns)\n",
    "        return attn\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout=True):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = RelationMultiheadAttention(embed_dim, num_heads, dropout, weights_dropout)\n",
    "        self.fc1 = nn.Linear(embed_dim, ff_embed_dim)\n",
    "        self.fc2 = nn.Linear(ff_embed_dim, embed_dim)\n",
    "        self.attn_layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = dropout\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.fc1.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc2.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0.)\n",
    "        nn.init.constant_(self.fc2.bias, 0.)\n",
    "\n",
    "    def forward(self, x, relation, kv = None,\n",
    "                self_padding_mask = None, self_attn_mask = None,\n",
    "                need_weights = False):\n",
    "        # x: seq_len x bsz x embed_dim\n",
    "        residual = x\n",
    "        if kv is None:\n",
    "            x, self_attn = self.self_attn(query=x, key=x, value=x, relation=relation, key_padding_mask=self_padding_mask, attn_mask=self_attn_mask, need_weights=need_weights)\n",
    "        else:\n",
    "            x, self_attn = self.self_attn(query=x, key=kv, value=kv, relation=relation, key_padding_mask=self_padding_mask, attn_mask=self_attn_mask, need_weights=need_weights)\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.attn_layer_norm(residual + x)\n",
    "\n",
    "        residual = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.ff_layer_norm(residual + x)\n",
    "        return x, self_attn\n",
    "\n",
    "class RelationMultiheadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., weights_dropout=True):\n",
    "        super(RelationMultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "\n",
    "        self.in_proj_weight = Parameter(torch.Tensor(3 * embed_dim, embed_dim))\n",
    "        self.in_proj_bias = Parameter(torch.Tensor(3 * embed_dim))\n",
    "        self.relation_in_proj = nn.Linear(embed_dim, 2*embed_dim, bias=False)\n",
    "\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=True)\n",
    "        self.weights_dropout = weights_dropout\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.in_proj_weight, std=0.02)\n",
    "        nn.init.normal_(self.out_proj.weight, std=0.02)\n",
    "        nn.init.normal_(self.relation_in_proj.weight, std=0.02)\n",
    "        nn.init.constant_(self.in_proj_bias, 0.)\n",
    "        nn.init.constant_(self.out_proj.bias, 0.)\n",
    "\n",
    "    def forward(self, query, key, value, relation, key_padding_mask=None, attn_mask=None, need_weights=False):\n",
    "        \"\"\" Input shape: Time x Batch x Channel\n",
    "            relation:  tgt_len x src_len x bsz x dim\n",
    "            key_padding_mask: Time x batch\n",
    "            attn_mask:  tgt_len x src_len\n",
    "        \"\"\"\n",
    "        qkv_same = query.data_ptr() == key.data_ptr() == value.data_ptr()\n",
    "        kv_same = key.data_ptr() == value.data_ptr()\n",
    "\n",
    "        tgt_len, bsz, embed_dim = query.size()\n",
    "        src_len = key.size(0)\n",
    "        assert key.size() == value.size()\n",
    "\n",
    "        if qkv_same:\n",
    "            # self-attention\n",
    "            q, k, v = self.in_proj_qkv(query)\n",
    "        elif kv_same:\n",
    "            # encoder-decoder attention\n",
    "            q = self.in_proj_q(query)\n",
    "            k, v = self.in_proj_kv(key)\n",
    "        else:\n",
    "            q = self.in_proj_q(query)\n",
    "            k = self.in_proj_k(key)\n",
    "            v = self.in_proj_v(value)\n",
    "\n",
    "        q = q.contiguous().view(tgt_len, bsz * self.num_heads, self.head_dim)\n",
    "        k = k.contiguous().view(src_len, bsz * self.num_heads, self.head_dim)\n",
    "        v = v.contiguous().view(src_len, bsz * self.num_heads, self.head_dim)\n",
    "\n",
    "        ra, rb = self.relation_in_proj(relation).chunk(2, dim=-1)\n",
    "        ra = ra.contiguous().view(tgt_len, src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n",
    "        rb = rb.contiguous().view(tgt_len, src_len, bsz * self.num_heads, self.head_dim).transpose(0, 1)\n",
    "\n",
    "        q = q.unsqueeze(1) + ra\n",
    "        k = k.unsqueeze(0) + rb\n",
    "        q *= self.scaling\n",
    "        # q: tgt_len x src_len x bsz*heads x dim\n",
    "        # k: tgt_len x src_len x bsz*heads x dim\n",
    "        # v: src_len x bsz*heads x dim\n",
    "\n",
    "        attn_weights = torch.einsum('ijbn,ijbn->ijb', [q, k])\n",
    "        assert list(attn_weights.size()) == [tgt_len, src_len, bsz * self.num_heads]\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_weights.masked_fill_(\n",
    "                attn_mask.unsqueeze(-1),\n",
    "                float('-inf')\n",
    "            )\n",
    "\n",
    "        if key_padding_mask is not None:\n",
    "            # don't attend to padding symbols\n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz, self.num_heads)\n",
    "            attn_weights.masked_fill_(\n",
    "                key_padding_mask.unsqueeze(0).unsqueeze(-1),\n",
    "                float('-inf')\n",
    "            )\n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz * self.num_heads)\n",
    "\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=1)\n",
    "\n",
    "        if self.weights_dropout:\n",
    "            attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        # attn_weights: tgt_len x src_len x bsz*heads\n",
    "        # v: src_len x bsz*heads x dim\n",
    "        attn = torch.einsum('ijb,jbn->bin', [attn_weights, v])\n",
    "        if not self.weights_dropout:\n",
    "            attn = F.dropout(attn, p=self.dropout, training=self.training)\n",
    "\n",
    "        assert list(attn.size()) == [bsz * self.num_heads, tgt_len, self.head_dim]\n",
    "\n",
    "        attn = attn.transpose(0, 1).contiguous().view(tgt_len, bsz, embed_dim)\n",
    "        attn = self.out_proj(attn)\n",
    "\n",
    "        if need_weights:\n",
    "            # maximum attention weight over heads \n",
    "            attn_weights = attn_weights.view(tgt_len, src_len, bsz, self.num_heads)\n",
    "        else:\n",
    "            attn_weights = None\n",
    "\n",
    "        return attn, attn_weights\n",
    "\n",
    "    def in_proj_qkv(self, query):\n",
    "        return self._in_proj(query).chunk(3, dim=-1)\n",
    "\n",
    "    def in_proj_kv(self, key):\n",
    "        return self._in_proj(key, start=self.embed_dim).chunk(2, dim=-1)\n",
    "\n",
    "    def in_proj_q(self, query):\n",
    "        return self._in_proj(query, end=self.embed_dim)\n",
    "\n",
    "    def in_proj_k(self, key):\n",
    "        return self._in_proj(key, start=self.embed_dim, end=2 * self.embed_dim)\n",
    "\n",
    "    def in_proj_v(self, value):\n",
    "        return self._in_proj(value, start=2 * self.embed_dim)\n",
    "\n",
    "    def _in_proj(self, input, start=0, end=None):\n",
    "        weight = self.in_proj_weight\n",
    "        bias = self.in_proj_bias\n",
    "        weight = weight[start:end, :]\n",
    "        if bias is not None:\n",
    "            bias = bias[start:end]\n",
    "        return F.linear(input, weight, bias)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'ogbg-moltox21'\n",
    "args.n_classes = 12\n",
    "# args.batch_size = 66666\n",
    "args.batch_size = 32\n",
    "args.lr = 0.001\n",
    "args.graph_pooling = 'mean'\n",
    "args.proj_mode = 'nonlinear'\n",
    "args.eval_metric = 'rocauc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "class GraphTransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, nclasses, layers, embed_dim, ff_embed_dim, num_heads, dropout, relation_type='link', max_vocab=2, weights_dropout=True):\n",
    "        super(GraphTransformerModel, self).__init__()\n",
    "        self.model_type = 'GraphTransformerModel'\n",
    "        self.encoder = AtomEncoder(emb_dim=embed_dim)\n",
    "        self.transformer = GraphTransformer(layers, embed_dim, ff_embed_dim, num_heads, dropout, weights_dropout)\n",
    "        \n",
    "        #Different kind of graph pooling\n",
    "        if args.graph_pooling == \"sum\":\n",
    "            self.graph_pool = global_add_pool\n",
    "        elif args.graph_pooling == \"mean\":\n",
    "            self.graph_pool = global_mean_pool\n",
    "        elif args.graph_pooling == \"max\":\n",
    "            self.graph_pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "        \n",
    "        self.task_pred = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, nclasses)\n",
    "        )\n",
    "        \n",
    "        self.relation_type = relation_type\n",
    "        self.max_vocab = max_vocab\n",
    "        self.relation_encoder = nn.Embedding(max_vocab, embed_dim)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        x, mask = to_dense_batch(self.encoder(src.x), batch=src.batch, fill_value=0)\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        if self.relation_type == 'link':\n",
    "            relation = self.relation_encoder(to_dense_adj(src.edge_index, batch=src.batch, max_num_nodes=x.size(0)).long())\n",
    "        elif self.relation_type == 'shortest_dist':\n",
    "            mod_sd_edge_attr = torch.clamp(src.sd_edge_attr.reshape(-1), 0, self.max_vocab - 1).long()\n",
    "            relation = self.relation_encoder(to_dense_adj(src.sd_edge_index, batch=src.batch, edge_attr=mod_sd_edge_attr, max_num_nodes=x.size(0)).long())\n",
    "        else:\n",
    "            raise ValueError(\"Invalid relation type.\")\n",
    "        \n",
    "        relation = relation.permute(2, 1, 0, 3)\n",
    "        \n",
    "        output = self.transformer(x, relation, self_padding_mask=~mask.transpose(0, 1))\n",
    "        \n",
    "        graph_emb = self.graph_pool(output.transpose(0, 1)[mask], src.batch)\n",
    "        graph_pred = self.task_pred(graph_emb)\n",
    "        \n",
    "        return graph_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.shortest_paths.generic import shortest_path \n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def compute_mutual_shortest_distances(d):\n",
    "    d_nx = to_networkx(d, to_undirected=True)\n",
    "    p = shortest_path(d_nx)\n",
    "    \n",
    "    sd_edge_index = torch.LongTensor(2, d.x.size(0) * d.x.size(0))\n",
    "    sd_edge_attr = torch.FloatTensor(d.x.size(0) * d.x.size(0), 1)\n",
    "    for i in range(d.x.size(0)):\n",
    "        for j in range(d.x.size(0)):\n",
    "            sd_edge_index[0][i * d.x.size(0) + j] = i\n",
    "            sd_edge_index[1][i * d.x.size(0) + j] = j\n",
    "            \n",
    "            if j in p[i]:\n",
    "                sd_edge_attr[i * d.x.size(0) + j] = len(p[i][j]) - 1\n",
    "            else:\n",
    "                sd_edge_attr[i * d.x.size(0) + j] = float(\"inf\")\n",
    "        \n",
    "    return Data(x=d.x, y=d.y, edge_index=d.edge_index, edge_attr=d.edge_attr, sd_edge_index=sd_edge_index, sd_edge_attr=sd_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "dataset: ogbg-moltox21 \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "print(\"dataset: {} \".format(args.dataset))\n",
    "dataset = PygGraphPropPredDataset(name=args.dataset, pre_transform=compute_mutual_shortest_distances).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2883888626709962\n",
      "Test loss: 0.20814052782952785\n",
      "Test ROC-AUC: 0.7035272323319242\n",
      "Train loss: 0.23447250674168268\n",
      "Test loss: 0.19820111927886805\n",
      "Test ROC-AUC: 0.7585388441275618\n",
      "Train loss: 0.22510698284858313\n",
      "Test loss: 0.2136251258974274\n",
      "Test ROC-AUC: 0.7505495325943894\n",
      "Train loss: 0.21678264423822746\n",
      "Test loss: 0.19854583560178676\n",
      "Test ROC-AUC: 0.7841156793109488\n",
      "Train loss: 0.2100631104829984\n",
      "Test loss: 0.188605978153646\n",
      "Test ROC-AUC: 0.8089104809959776\n",
      "Train loss: 0.20404184747200746\n",
      "Test loss: 0.2001753974085053\n",
      "Test ROC-AUC: 0.8085986419939064\n",
      "Train loss: 0.20162073484598061\n",
      "Test loss: 0.18933032701412836\n",
      "Test ROC-AUC: 0.8162035286709562\n",
      "Train loss: 0.1979082756317579\n",
      "Test loss: 0.18093874771147966\n",
      "Test ROC-AUC: 0.8244953730753369\n",
      "Train loss: 0.1945814794454819\n",
      "Test loss: 0.18208417731026807\n",
      "Test ROC-AUC: 0.8191403903878385\n",
      "Train loss: 0.1925411995404806\n",
      "Test loss: 0.18119632576902708\n",
      "Test ROC-AUC: 0.8252339506625752\n",
      "Train loss: 0.19086528512147757\n",
      "Test loss: 0.1788252405822277\n",
      "Test ROC-AUC: 0.8312859948477539\n",
      "Train loss: 0.18832096415452468\n",
      "Test loss: 0.18171404240032038\n",
      "Test ROC-AUC: 0.8345666923539716\n",
      "Train loss: 0.18647186102775426\n",
      "Test loss: 0.18205832100162903\n",
      "Test ROC-AUC: 0.8257012379838645\n",
      "Train loss: 0.18534529988582318\n",
      "Test loss: 0.18022496967266002\n",
      "Test ROC-AUC: 0.829714851793283\n",
      "Train loss: 0.1821104183410987\n",
      "Test loss: 0.17969663379093012\n",
      "Test ROC-AUC: 0.8404076725529007\n",
      "Train loss: 0.18060909265126937\n",
      "Test loss: 0.17928713808457056\n",
      "Test ROC-AUC: 0.8361477675454291\n",
      "Train loss: 0.17979547125406756\n",
      "Test loss: 0.1797330199430386\n",
      "Test ROC-AUC: 0.8360391635898048\n",
      "Train loss: 0.1789303922882447\n",
      "Test loss: 0.17985873421033224\n",
      "Test ROC-AUC: 0.8423968112058008\n",
      "Train loss: 0.17708422136612428\n",
      "Test loss: 0.1821227182323734\n",
      "Test ROC-AUC: 0.8352749836425071\n",
      "Train loss: 0.1770146825374701\n",
      "Test loss: 0.1763117192313075\n",
      "Test ROC-AUC: 0.845994862542593\n",
      "Train loss: 0.17435622528577463\n",
      "Test loss: 0.17941765456149975\n",
      "Test ROC-AUC: 0.8416985807524676\n",
      "Train loss: 0.17305727436756477\n",
      "Test loss: 0.18918626382946968\n",
      "Test ROC-AUC: 0.8332454944278077\n",
      "Train loss: 0.17166135972126936\n",
      "Test loss: 0.17767752334475517\n",
      "Test ROC-AUC: 0.8430819944128358\n",
      "Train loss: 0.16932989209890364\n",
      "Test loss: 0.17890786690016589\n",
      "Test ROC-AUC: 0.8369644083630158\n",
      "Train loss: 0.16819449728116012\n",
      "Test loss: 0.18153828599800667\n",
      "Test ROC-AUC: 0.8381366023624622\n",
      "Train loss: 0.16631705184013415\n",
      "Test loss: 0.1806617360562086\n",
      "Test ROC-AUC: 0.8381501629932546\n",
      "Train loss: 0.16618468727056795\n",
      "Test loss: 0.18064371900012097\n",
      "Test ROC-AUC: 0.8440700045075458\n",
      "Train loss: 0.16480821520090103\n",
      "Test loss: 0.1820177063345909\n",
      "Test ROC-AUC: 0.8370273782158089\n",
      "Train loss: 0.16346004055096552\n",
      "Test loss: 0.18413663189858198\n",
      "Test ROC-AUC: 0.8396038451055072\n",
      "Train loss: 0.16121948514229212\n",
      "Test loss: 0.177433584506313\n",
      "Test ROC-AUC: 0.8375663068227236\n",
      "Train loss: 0.16200437133128825\n",
      "Test loss: 0.17721661366522312\n",
      "Test ROC-AUC: 0.846315014371482\n",
      "Train loss: 0.1616165076692899\n",
      "Test loss: 0.18923457028965154\n",
      "Test ROC-AUC: 0.8311754235653382\n",
      "Train loss: 0.16003341055833376\n",
      "Test loss: 0.1868345287318031\n",
      "Test ROC-AUC: 0.8285212373972083\n",
      "Train loss: 0.1584867613437848\n",
      "Test loss: 0.18345831024150053\n",
      "Test ROC-AUC: 0.831840176801027\n",
      "Train loss: 0.15917886594931285\n",
      "Test loss: 0.18352150544524193\n",
      "Test ROC-AUC: 0.8311635246415007\n",
      "Train loss: 0.15577039978443047\n",
      "Test loss: 0.18220083508640528\n",
      "Test ROC-AUC: 0.8466036589615284\n",
      "Train loss: 0.15655509787492264\n",
      "Test loss: 0.18590049352496862\n",
      "Test ROC-AUC: 0.8369047923318153\n",
      "Train loss: 0.16291053833869787\n",
      "Test loss: 0.18906695147355398\n",
      "Test ROC-AUC: 0.8269925054172943\n",
      "Train loss: 0.1587445562848678\n",
      "Test loss: 0.18390046432614326\n",
      "Test ROC-AUC: 0.8275441841018921\n",
      "Train loss: 0.1565435107701864\n",
      "Test loss: 0.18921497277915478\n",
      "Test ROC-AUC: 0.8346712399916468\n",
      "Train loss: 0.15353419127372595\n",
      "Test loss: 0.19162454238782325\n",
      "Test ROC-AUC: 0.8238670513860472\n",
      "Train loss: 0.15349041380179235\n",
      "Test loss: 0.18532322191943726\n",
      "Test ROC-AUC: 0.8281964023789996\n",
      "Train loss: 0.15339788534702398\n",
      "Test loss: 0.18721325074632963\n",
      "Test ROC-AUC: 0.8261109508535472\n",
      "Train loss: 0.15142736511352733\n",
      "Test loss: 0.190709606744349\n",
      "Test ROC-AUC: 0.8340677901804905\n",
      "Train loss: 0.1513733012171892\n",
      "Test loss: 0.1897708484902978\n",
      "Test ROC-AUC: 0.817145683187857\n",
      "Train loss: 0.14785794829710935\n",
      "Test loss: 0.18686662490169206\n",
      "Test ROC-AUC: 0.8274378522849098\n",
      "Train loss: 0.1482658203213643\n",
      "Test loss: 0.1995280267049869\n",
      "Test ROC-AUC: 0.8255806995938529\n",
      "Train loss: 0.14643481167463157\n",
      "Test loss: 0.19583006296306849\n",
      "Test ROC-AUC: 0.8178731050684438\n",
      "Train loss: 0.1455126316883625\n",
      "Test loss: 0.18812680058181286\n",
      "Test ROC-AUC: 0.8302366701235134\n",
      "Train loss: 0.14381912457637297\n",
      "Test loss: 0.19278311418990293\n",
      "Test ROC-AUC: 0.8298534577273089\n"
     ]
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "# train_loader = DataLoader(dataset[:int(0.8 * len(dataset))], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "# test_loader = DataLoader(dataset[int(0.8 * len(dataset)):], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# embed_dim = 512\n",
    "embed_dim = 128\n",
    "# ff_embed_dim = 1024\n",
    "ff_embed_dim = 256\n",
    "num_heads = 8\n",
    "# graph_layers = 4\n",
    "graph_layers = 2\n",
    "dropout = 0.2\n",
    "# relation_type = 'shortest_dist'\n",
    "relation_type = 'link'\n",
    "max_vocab = 12\n",
    "model = GraphTransformerModel(args.n_classes, graph_layers, embed_dim, ff_embed_dim, num_heads, dropout, relation_type, max_vocab).to(args.device)\n",
    "\n",
    "# To train Transformer, better to use the default hyperparameter for optimizer and LR scheduler.\n",
    "# You can refer to some latest code as a reference.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "evaluator = Evaluator(name=args.dataset)\n",
    "\n",
    "args.num_epochs = 50\n",
    "for epoch in range(args.num_epochs):\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_epoch = 0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        z = model(batch.to(args.device))\n",
    "\n",
    "        y = batch.y.float()\n",
    "        is_valid = ~torch.isnan(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(z[is_valid], y[is_valid])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    print('Train loss:', loss_epoch / len(train_loader))\n",
    "    \n",
    "    ##############\n",
    "    # EVALUATION #\n",
    "    ##############\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_epoch = 0\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            z = model(batch.to(args.device))\n",
    "\n",
    "            y = batch.y.float()\n",
    "            y_true.append(y)\n",
    "            y_scores.append(z)\n",
    "            is_valid = ~torch.isnan(y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(z[is_valid], y[is_valid])\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim = 0)\n",
    "        y_scores = torch.cat(y_scores, dim = 0)\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_scores}\n",
    "    result_dict = evaluator.eval(input_dict)\n",
    "    print('Test loss:', loss_epoch / len(test_loader))\n",
    "    print('Test ROC-AUC:', result_dict[args.eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual shortest path between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison to SOTA (copy from GIN notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
