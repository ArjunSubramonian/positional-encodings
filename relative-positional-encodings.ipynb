{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch_geometric.transforms as T\n",
    "from torch import lgamma\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_mean\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import ogb\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of relative positional encodings for graph Transformers')\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 3\n",
    "args.device = torch.device('cuda:'+ str(args.device) if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", args.device)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention_RPR(nn.Module):\n",
    "    def __init__(self, d_model, h, vocab_size=2, dropout=.0):\n",
    "        \"\"\"\n",
    "        multi-head attention\n",
    "        :param h: nhead\n",
    "        :param d_model: d_model\n",
    "        :param dropout: float\n",
    "        \"\"\"\n",
    "        super(MultiHeadedAttention_RPR, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        #  assume d_v always equals d_k\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for i in range(4)])\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_K = nn.Embedding(self.vocab_size, self.d_k)\n",
    "        self.embed_V = nn.Embedding(self.vocab_size, self.d_k)\n",
    "\n",
    "    def forward(self, query, key, value, rpr_matrix, mask=None):\n",
    "        nbatches = query.size(0)  # batch size\n",
    "        seq_len = query.size(1)\n",
    "        # 1) split embedding dim to h heads : from d_model => h * d_k\n",
    "        # dim: (nbatch, h, seq_length, d_model//h)\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) rpr\n",
    "        assert rpr_matrix.size(1) == seq_len and rpr_matrix.size(2) == seq_len\n",
    "        relation_keys = self.embed_K(rpr_matrix)\n",
    "        relation_values = self.embed_V(rpr_matrix)\n",
    "        logits = self._relative_attn_inner(query, key, relation_keys, True)\n",
    "        weights = self.dropout(F.softmax(logits, -1))\n",
    "        x = self._relative_attn_inner(weights, value, relation_values, False)\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "    def _relative_attn_inner(self, x, y, z, transpose):\n",
    "        nbatches = x.size(0)\n",
    "        heads = x.size(1)\n",
    "        seq_len = x.size(2)\n",
    "\n",
    "        # (N, h, s, d) @ (N, h, d, s) => (N, h, s, s)\n",
    "        # (N, h, s, s) @ (N, h, s, d) => (N, h, s, d)\n",
    "        xy_matmul = torch.matmul(x, y.transpose(-1, -2) if transpose else y)\n",
    "        # (s, N, h, d)\n",
    "        # (s, N, h, s)\n",
    "        x_t_v = x.permute(2, 0, 1, 3).contiguous()\n",
    "        # (s, N, h, d) @ (s, N, d, s) => (s, N, h, s)\n",
    "        # (s, N, h, s) @ (s, N, s, d) => (s, N, h, d)\n",
    "        x_tz_matmul = torch.matmul(x_t_v, z.permute(1, 0, 3, 2) if transpose else z.transpose(0, 1))\n",
    "        # (N, h, s, s)\n",
    "        # (N, h, s, d)\n",
    "        x_tz_matmul_v_t = x_tz_matmul.permute(1, 2, 0, 3)\n",
    "        return xy_matmul + x_tz_matmul_v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "\n",
    "    raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))\n",
    "\n",
    "class TransformerEncoderLayer(Module):\n",
    "    r\"\"\"TransformerEncoderLayer is made up of self-attn and feedforward network.\n",
    "    This standard encoder layer is based on the paper \"Attention Is All You Need\".\n",
    "    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
    "    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in\n",
    "    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement\n",
    "    in a different way during application.\n",
    "\n",
    "    Args:\n",
    "        d_model: the number of expected features in the input (required).\n",
    "        nhead: the number of heads in the multiheadattention models (required).\n",
    "        dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "\n",
    "    Examples::\n",
    "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        >>> src = torch.rand(10, 32, 512)\n",
    "        >>> out = encoder_layer(src)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.0, activation=\"relu\"):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention_RPR(d_model, nhead, 2, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = Linear(d_model, dim_feedforward)\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.linear2 = Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(TransformerEncoderLayer, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, src, rpr_matrix, src_mask):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            src: the sequence to the encoder layer (required).\n",
    "            src_mask: the mask for the src sequence (optional).\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        src2 = self.self_attn(src, src, src, rpr_matrix, mask=src_mask)[0]\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n",
    "\n",
    "class TransformerEncoder(Module):\n",
    "    r\"\"\"TransformerEncoder is a stack of N encoder layers\n",
    "\n",
    "    Args:\n",
    "        encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "        num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "        norm: the layer normalization component (optional).\n",
    "\n",
    "    Examples::\n",
    "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        >>> src = torch.rand(10, 32, 512)\n",
    "        >>> out = transformer_encoder(src)\n",
    "    \"\"\"\n",
    "    __constants__ = ['norm']\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, rpr_matrix, mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layers in turn.\n",
    "\n",
    "        Args:\n",
    "            src: the sequence to the encoder (required).\n",
    "            mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        output = src\n",
    "\n",
    "        for mod in self.layers:\n",
    "            output = mod(output, rpr_matrix, src_mask=mask)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset = 'ogbg-moltox21'\n",
    "args.n_classes = 12\n",
    "args.batch_size = 128\n",
    "args.lr = 0.001\n",
    "args.graph_pooling = 'mean'\n",
    "args.proj_mode = 'nonlinear'\n",
    "args.eval_metric = 'rocauc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, nclasses, ninp, nhead, nhid, nlayers, dropout=0.0):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        # self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = AtomEncoder(emb_dim=ninp)\n",
    "        self.ninp = ninp\n",
    "        \n",
    "        #Different kind of graph pooling\n",
    "        if args.graph_pooling == \"sum\":\n",
    "            self.graph_pool = global_add_pool\n",
    "        elif args.graph_pooling == \"mean\":\n",
    "            self.graph_pool = global_mean_pool\n",
    "        elif args.graph_pooling == \"max\":\n",
    "            self.graph_pool = global_max_pool\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "              \n",
    "        #One more MLP to project the final embedding\n",
    "        if args.proj_mode == 'linear':\n",
    "            self.projector = nn.Linear(nhid, nhid, bias=False)\n",
    "        elif args.proj_mode == 'nonlinear':\n",
    "            self.projector = nn.Sequential(\n",
    "                nn.Linear(nhid, nhid),\n",
    "                nn.BatchNorm1d(nhid),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhid, nhid, bias=False)\n",
    "            )\n",
    "        \n",
    "        self.task_pred = nn.Sequential(\n",
    "            nn.Linear(nhid, nhid),\n",
    "            nn.BatchNorm1d(nhid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhid, nclasses)\n",
    "        )\n",
    "\n",
    "    # is mask needed?\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, src_mask=None): \n",
    "#         data_list = src.to_data_list()\n",
    "#         seq_len = torch.max(torch.unique(src.batch, return_counts=True)[1])\n",
    "    \n",
    "#         raw_features = torch.stack([F.pad(input=self.encoder(d.x), pad=(0, 0, 0, seq_len - d.x.size(0))) for d in data_list])\n",
    "#         dense_adj_list = [to_dense_adj(d.edge_index)[0] for d in data_list]\n",
    "#         rpr_matrix = torch.stack([F.pad(input=d, pad=(0, seq_len - d.size(1), 0, seq_len - d.size(0))) for d in dense_adj_list]).long()\n",
    "#         print(raw_features.size(), rpr_matrix.size())\n",
    "        \n",
    "        raw_features, mask = to_dense_batch(self.encoder(src.x), batch=src.batch, fill_value=0)\n",
    "        rpr_matrix = to_dense_adj(src.edge_index, batch=src.batch, max_num_nodes=raw_features.size(1)).long()\n",
    "#         print(raw_features.size(), rpr_matrix.size())\n",
    "        \n",
    "        output = self.transformer_encoder(raw_features, rpr_matrix, src_mask)\n",
    "        \n",
    "        graph_emb = self.graph_pool(output[mask], src.batch)   \n",
    "        graph_pred = self.task_pred(graph_emb)\n",
    "        \n",
    "        return graph_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "dataset: ogbg-moltox21 \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "print(\"dataset: {} \".format(args.dataset))\n",
    "dataset = PygGraphPropPredDataset(name=args.dataset).shuffle()\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=len(dataset), shuffle=False, drop_last=True)\n",
    "\n",
    "# for idx, batch in enumerate(loader):\n",
    "#     data_list = batch.to_data_list()\n",
    "#     seq_len = max([d.x.size(0) for d in data_list])\n",
    "# print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3840306888644894\n",
      "Test loss: 0.47244936724503833\n",
      "Test ROC-AUC: 0.6078850311304983\n",
      "Train loss: 0.24866258477171263\n",
      "Test loss: 0.45485736678044003\n",
      "Test ROC-AUC: 0.6278808713535898\n",
      "Train loss: 0.23447011100749174\n",
      "Test loss: 0.5805706158280373\n",
      "Test ROC-AUC: 0.6404235296482289\n",
      "Train loss: 0.22544364413867393\n",
      "Test loss: 0.6687075396378835\n",
      "Test ROC-AUC: 0.5747901133884529\n",
      "Train loss: 0.21939901914447546\n",
      "Test loss: 0.32966379697124165\n",
      "Test ROC-AUC: 0.6951001083494525\n",
      "Train loss: 0.21761066373437643\n",
      "Test loss: 1.5294218858083088\n",
      "Test ROC-AUC: 0.5897350719471978\n",
      "Train loss: 0.21375601335118213\n",
      "Test loss: 0.7790202548106512\n",
      "Test ROC-AUC: 0.560669036097115\n",
      "Train loss: 0.21132949894915024\n",
      "Test loss: 0.524609386920929\n",
      "Test ROC-AUC: 0.6774632435590905\n",
      "Train loss: 0.2137811646486322\n",
      "Test loss: 0.49296770989894867\n",
      "Test ROC-AUC: 0.6868637310273492\n",
      "Train loss: 0.21225193267067274\n",
      "Test loss: 0.7828775122761726\n",
      "Test ROC-AUC: 0.5962532311141459\n",
      "Train loss: 0.20729540505756935\n",
      "Test loss: 0.9277635912100474\n",
      "Test ROC-AUC: 0.6150400570299482\n",
      "Train loss: 0.20567792219420275\n",
      "Test loss: 0.9389290511608124\n",
      "Test ROC-AUC: 0.5751590776159378\n",
      "Train loss: 0.20914371125400066\n",
      "Test loss: 0.5684855257471403\n",
      "Test ROC-AUC: 0.6400363833096255\n",
      "Train loss: 0.2115988334019979\n",
      "Test loss: 0.6347599079211553\n",
      "Test ROC-AUC: 0.6622611915259918\n",
      "Train loss: 0.20436715396742025\n",
      "Test loss: 0.5122272819280624\n",
      "Test ROC-AUC: 0.6831990693429875\n",
      "Train loss: 0.20243366590390602\n",
      "Test loss: 0.4493175173799197\n",
      "Test ROC-AUC: 0.6696394243035155\n",
      "Train loss: 0.2011218722909689\n",
      "Test loss: 0.4408634702364604\n",
      "Test ROC-AUC: 0.7251109538707564\n",
      "Train loss: 0.1986911582450072\n",
      "Test loss: 0.5071467558542887\n",
      "Test ROC-AUC: 0.6849251031294372\n",
      "Train loss: 0.19708363432437181\n",
      "Test loss: 0.37098710238933563\n",
      "Test ROC-AUC: 0.6740648725252832\n",
      "Train loss: 0.19550824320564666\n",
      "Test loss: 0.32012923310200375\n",
      "Test ROC-AUC: 0.6380594918689921\n",
      "Train loss: 0.1942730344211062\n",
      "Test loss: 0.6321951473752657\n",
      "Test ROC-AUC: 0.6080609674010832\n",
      "Train loss: 0.19693671135852733\n",
      "Test loss: 1.4250027139981587\n",
      "Test ROC-AUC: 0.6588116026259332\n",
      "Train loss: 0.1997637494156758\n",
      "Test loss: 0.7232244138916334\n",
      "Test ROC-AUC: 0.6626765188113309\n",
      "Train loss: 0.1942567608008782\n",
      "Test loss: 0.6045059735576311\n",
      "Test ROC-AUC: 0.6918102812635052\n",
      "Train loss: 0.1910337951655189\n",
      "Test loss: 0.4555068239569664\n",
      "Test ROC-AUC: 0.6830669087265179\n",
      "Train loss: 0.18945161113515496\n",
      "Test loss: 0.5152376542488734\n",
      "Test ROC-AUC: 0.6566428902027759\n",
      "Train loss: 0.19079446389029422\n",
      "Test loss: 0.6124163344502449\n",
      "Test ROC-AUC: 0.7136854169706902\n",
      "Train loss: 0.1924425708130002\n",
      "Test loss: 0.6750932807723681\n",
      "Test ROC-AUC: 0.6853555015110397\n",
      "Train loss: 0.19235044376303753\n",
      "Test loss: 0.6547436813513438\n",
      "Test ROC-AUC: 0.6646644572675293\n",
      "Train loss: 0.1882157955939571\n",
      "Test loss: 0.48412681619326275\n",
      "Test ROC-AUC: 0.6786258168548219\n",
      "Train loss: 0.18832733606298765\n",
      "Test loss: 0.37379412601391476\n",
      "Test ROC-AUC: 0.632734656718945\n",
      "Train loss: 0.1892555272206664\n",
      "Test loss: 1.0731394191582997\n",
      "Test ROC-AUC: 0.6627751888689631\n",
      "Train loss: 0.18860544357448816\n",
      "Test loss: 0.8499315828084946\n",
      "Test ROC-AUC: 0.6765356940121934\n",
      "Train loss: 0.18529298342764378\n",
      "Test loss: 0.7598569865028063\n",
      "Test ROC-AUC: 0.6331249721181796\n",
      "Train loss: 0.18910336556533971\n",
      "Test loss: 0.9494818051656088\n",
      "Test ROC-AUC: 0.6557441249223378\n",
      "Train loss: 0.1863303535307447\n",
      "Test loss: 0.5466638629635175\n",
      "Test ROC-AUC: 0.6481628501693348\n",
      "Train loss: 0.18385210943718752\n",
      "Test loss: 0.46874534835418064\n",
      "Test ROC-AUC: 0.6303405388505973\n",
      "Train loss: 0.18559241791566214\n",
      "Test loss: 0.6117009197672209\n",
      "Test ROC-AUC: 0.6987154870041491\n",
      "Train loss: 0.19101375403503576\n",
      "Test loss: 1.8575951755046844\n",
      "Test ROC-AUC: 0.6228639130763038\n",
      "Train loss: 0.1964716538786888\n",
      "Test loss: 1.8701273798942566\n",
      "Test ROC-AUC: 0.622551715723187\n",
      "Train loss: 0.1914833557481567\n",
      "Test loss: 1.516329030195872\n",
      "Test ROC-AUC: 0.642473224022985\n",
      "Train loss: 0.1866931626573205\n",
      "Test loss: 1.1067321946223576\n",
      "Test ROC-AUC: 0.6118853406201556\n",
      "Train loss: 0.18443887634202838\n",
      "Test loss: 1.262329523762067\n",
      "Test ROC-AUC: 0.6098799723397894\n",
      "Train loss: 0.18215765819574395\n",
      "Test loss: 0.6076101859410604\n",
      "Test ROC-AUC: 0.6495331614743906\n",
      "Train loss: 0.18269766060014567\n",
      "Test loss: 1.5003873805205028\n",
      "Test ROC-AUC: 0.6131505740908606\n",
      "Train loss: 0.18041886296123266\n",
      "Test loss: 1.357125888268153\n",
      "Test ROC-AUC: 0.7126282879539328\n",
      "Train loss: 0.17768404337887964\n",
      "Test loss: 0.481634962062041\n",
      "Test ROC-AUC: 0.7122510934318611\n",
      "Train loss: 0.17423969445129237\n",
      "Test loss: 0.7094169209400812\n",
      "Test ROC-AUC: 0.6701541003208961\n",
      "Train loss: 0.1764153029459218\n",
      "Test loss: 1.167558918396632\n",
      "Test ROC-AUC: 0.6251301606305609\n",
      "Train loss: 0.1752071105875075\n",
      "Test loss: 0.6921286856134733\n",
      "Test ROC-AUC: 0.6345479369802353\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset[:int(0.8 * len(dataset))], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(dataset[int(0.8 * len(dataset)):], batch_size=args.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.0 # the dropout value\n",
    "model = TransformerModel(args.n_classes, emsize, nhead, nhid, nlayers, dropout).to(args.device)\n",
    "\n",
    "# To train Transformer, better to use the default hyperparameter for optimizer and LR scheduler.\n",
    "# You can refer to some latest code as a reference.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "evaluator = Evaluator(name=args.dataset)\n",
    "\n",
    "args.num_epochs = 50\n",
    "for epoch in range(args.num_epochs):\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_epoch = 0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        z = model(batch.to(args.device))\n",
    "\n",
    "        y = batch.y.float()\n",
    "        is_valid = ~torch.isnan(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(z[is_valid], y[is_valid])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    print('Train loss:', loss_epoch / len(train_loader))\n",
    "    \n",
    "    ##############\n",
    "    # EVALUATION #\n",
    "    ##############\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_epoch = 0\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        for idx, batch in enumerate(test_loader):\n",
    "            z = model(batch.to(args.device))\n",
    "\n",
    "            y = batch.y.float()\n",
    "            y_true.append(y)\n",
    "            y_scores.append(z)\n",
    "            is_valid = ~torch.isnan(y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(z[is_valid], y[is_valid])\n",
    "\n",
    "            loss_epoch += loss.item()\n",
    "        \n",
    "        y_true = torch.cat(y_true, dim = 0)\n",
    "        y_scores = torch.cat(y_scores, dim = 0)\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_scores}\n",
    "    result_dict = evaluator.eval(input_dict)\n",
    "    print('Test loss:', loss_epoch / len(test_loader))\n",
    "    print('Test ROC-AUC:', result_dict[args.eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
