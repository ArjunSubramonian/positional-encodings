{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(adamic_edge_attr=[308, 1], alloc_edge_attr=[308, 1], cn_edge_attr=[308, 1], comm_edge_attr=[308, 1], edge_attr=[308, 3], edge_index=[2, 308], hier_label=[32, 4], hsd_edge_attr=[308, 4], jaccard_edge_attr=[308, 1], lap_x=[32, 10], orig_edge_attr=[70, 3], orig_edge_index=[2, 70], sd_edge_attr=[308, 1], x=[32, 9], y=[1, 1])\n",
      "torch.Size([70, 3])\n",
      "torch.Size([308, 3])\n",
      "tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.2500],\n",
      "        [0.0000],\n",
      "        [0.2500],\n",
      "        [0.2500],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.5000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.3333],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.2500],\n",
      "        [0.2500],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.2500],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]])\n",
      "torch.Size([70, 3])\n",
      "torch.Size([372, 3])\n",
      "tensor([[ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.7213],\n",
      "        [ 0.0000],\n",
      "        [ 0.7213],\n",
      "        [ 0.7213],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 1.4427],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.9102],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.7213],\n",
      "        [ 0.7213],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.7213],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import ogb\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from graph_transformer import GT\n",
    "from utils import pre_process, pre_process_with_summary, get_n_params, get_optimizer\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch implementation of relative positional encodings and relation-aware self-attention for graph Transformers')\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.dataset = 'ogbg-molhiv'\n",
    "args.n_classes = 1\n",
    "args.lr = 3e-4\n",
    "args.n_hid = 512\n",
    "args.n_heads = 8\n",
    "args.n_layer = 4\n",
    "args.dropout = 0.2\n",
    "args.num_epochs = 60\n",
    "args.k_hop_neighbors = 3\n",
    "args.weight_decay = 1e-2\n",
    "args.bsz      = 512\n",
    "args.strategies = ['ea', 'sd', 'ja']\n",
    "args.summary_node = True\n",
    "args.hier_levels = 3\n",
    "args.lap_k = 10\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.metric = 'rocauc'\n",
    "print(\"device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "dataset: ogbg-molhiv \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "print(\"dataset: {} \".format(args.dataset))\n",
    "tz = pytz.timezone('US/Pacific')\n",
    "time_now = datetime.datetime.now(tz).strftime('%m-%d_%H:%M:%S')\n",
    "\n",
    "if args.summary_node:\n",
    "    pre_transform = lambda d : pre_process_with_summary(d, args)\n",
    "    root_path= f'dataset/{args.dataset}/with_summary_{args.k_hop_neighbors}'\n",
    "    args.writer = SummaryWriter(log_dir=f'runs_new/{args.dataset}/with_summary_k={args.k_hop_neighbors}/strats={\"-\".join(args.strategies)}/{time_now}')\n",
    "\n",
    "else:\n",
    "    pre_transform = lambda d : pre_process(d, args)\n",
    "    root_path= f'dataset/{args.dataset}/{args.k_hop_neighbors}'\n",
    "    args.writer = SummaryWriter(log_dir=f'runs_new/{args.dataset}/k={args.k_hop_neighbors}/strats={\"-\".join(args.strategies)}/{time_now}')\n",
    "    \n",
    "    \n",
    "dataset = PygGraphPropPredDataset(name=args.dataset, pre_transform=pre_transform, root = root_path)\n",
    "evaluator = Evaluator(name=args.dataset)\n",
    "split_idx = dataset.get_idx_split()\n",
    "edge_dim_dict = {# 'ea': dataset.data.edge_attr.max(dim=0)[0].int().view(-1) + 1, \\\n",
    "                 'disc': {\n",
    "#                      'sd': (dataset.data.sd_edge_attr.max(dim=0)[0].int().view(-1) + 1).tolist(), \\\n",
    "#                      'cn': (dataset.data.cn_edge_attr.max(dim=0)[0].int().view(-1) + 1).tolist(), \\\n",
    "#                      'hsd': (dataset.data.hsd_edge_attr.max(dim=0)[0].int().view(-1) + 1).tolist(), \\\n",
    "                    },\n",
    "                 'cont': {\n",
    "                    'ja': args.n_hid, \\\n",
    "#                     'ad': dataset.data.adamic_edge_attr.max(dim=0)[0].int().view(-1) + 1, \\\n",
    "                 }\n",
    "                }\n",
    "model = GT(args.n_hid, args.n_classes, args.n_heads, args.n_layer, edge_dim_dict, args.dropout, args.summary_node, args.lap_k).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular loader\n",
    "# train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.bsz, shuffle=True)\n",
    "# valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.bsz, shuffle=False)\n",
    "# test_loader  = DataLoader(dataset[split_idx[\"test\"]],  batch_size=args.bsz, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader with weighted sampler, for unbalanced data\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "weight = [1.0, np.sqrt((dataset.data.y == 0).sum().item() / (dataset.data.y == 1).sum().item())]\n",
    "samples_weight = np.array([weight[yi] for yi in dataset.data.y.view(-1)[split_idx[\"train\"]]])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.bsz, sampler = sampler)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.bsz, shuffle = False)\n",
    "test_loader  = DataLoader(dataset[split_idx[\"test\"]],  batch_size=args.bsz, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #Params: 6666753\n"
     ]
    }
   ],
   "source": [
    "print('Model #Params: %d' % get_n_params(model))\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "\n",
    "# optimizer = get_optimizer(model, weight_decay = args.weight_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=args.lr, pct_start = 0.05,\\\n",
    "#         steps_per_epoch=len(train_loader), epochs = args.num_epochs, anneal_strategy = 'linear')\n",
    "\n",
    "optimizer = get_optimizer(model, weight_decay = args.weight_decay, learning_rate = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 500, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:00<00:00,  1.08it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.05it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: LR: 0.00029, Train loss: 0.448 Train rocauc: 0.605 Valid loss: 0.167  Valid rocauc: 0.751 Test loss: 0.198  Test rocauc: 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:58<00:00,  1.10it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.15it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: LR: 0.00025, Train loss: 0.377 Train rocauc: 0.751 Valid loss: 0.120  Valid rocauc: 0.766 Test loss: 0.145  Test rocauc: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:59<00:00,  1.10it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.12it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: LR: 0.00020, Train loss: 0.347 Train rocauc: 0.795 Valid loss: 0.126  Valid rocauc: 0.786 Test loss: 0.153  Test rocauc: 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.91it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: LR: 0.00014, Train loss: 0.327 Train rocauc: 0.825 Valid loss: 0.140  Valid rocauc: 0.787 Test loss: 0.169  Test rocauc: 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.90it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: LR: 0.00008, Train loss: 0.305 Train rocauc: 0.852 Valid loss: 0.146  Valid rocauc: 0.792 Test loss: 0.179  Test rocauc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:03<00:00,  1.02it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.93it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: LR: 0.00004, Train loss: 0.297 Train rocauc: 0.862 Valid loss: 0.125  Valid rocauc: 0.791 Test loss: 0.160  Test rocauc: 0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.98it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: LR: 0.00001, Train loss: 0.282 Train rocauc: 0.873 Valid loss: 0.123  Valid rocauc: 0.802 Test loss: 0.163  Test rocauc: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.03it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: LR: 0.00000, Train loss: 0.283 Train rocauc: 0.875 Valid loss: 0.131  Valid rocauc: 0.803 Test loss: 0.170  Test rocauc: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.97it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: LR: 0.00002, Train loss: 0.286 Train rocauc: 0.876 Valid loss: 0.121  Valid rocauc: 0.802 Test loss: 0.160  Test rocauc: 0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:03<00:00,  1.03it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.00it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: LR: 0.00006, Train loss: 0.282 Train rocauc: 0.878 Valid loss: 0.133  Valid rocauc: 0.792 Test loss: 0.177  Test rocauc: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.98it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: LR: 0.00012, Train loss: 0.279 Train rocauc: 0.880 Valid loss: 0.118  Valid rocauc: 0.798 Test loss: 0.154  Test rocauc: 0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.96it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: LR: 0.00018, Train loss: 0.278 Train rocauc: 0.885 Valid loss: 0.097  Valid rocauc: 0.829 Test loss: 0.127  Test rocauc: 0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:03<00:00,  1.03it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.01it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: LR: 0.00023, Train loss: 0.273 Train rocauc: 0.893 Valid loss: 0.087  Valid rocauc: 0.818 Test loss: 0.125  Test rocauc: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.89it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: LR: 0.00028, Train loss: 0.261 Train rocauc: 0.898 Valid loss: 0.097  Valid rocauc: 0.837 Test loss: 0.140  Test rocauc: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.87it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: LR: 0.00030, Train loss: 0.257 Train rocauc: 0.909 Valid loss: 0.108  Valid rocauc: 0.812 Test loss: 0.144  Test rocauc: 0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.02it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: LR: 0.00030, Train loss: 0.251 Train rocauc: 0.910 Valid loss: 0.127  Valid rocauc: 0.822 Test loss: 0.160  Test rocauc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:58<00:00,  1.12it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.16it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: LR: 0.00027, Train loss: 0.229 Train rocauc: 0.930 Valid loss: 0.148  Valid rocauc: 0.820 Test loss: 0.192  Test rocauc: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:00<00:00,  1.07it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.88it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: LR: 0.00022, Train loss: 0.214 Train rocauc: 0.938 Valid loss: 0.099  Valid rocauc: 0.804 Test loss: 0.145  Test rocauc: 0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.01it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.98it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: LR: 0.00016, Train loss: 0.201 Train rocauc: 0.949 Valid loss: 0.110  Valid rocauc: 0.824 Test loss: 0.164  Test rocauc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.85it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: LR: 0.00010, Train loss: 0.182 Train rocauc: 0.960 Valid loss: 0.130  Valid rocauc: 0.803 Test loss: 0.178  Test rocauc: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.00it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.99it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: LR: 0.00005, Train loss: 0.165 Train rocauc: 0.968 Valid loss: 0.108  Valid rocauc: 0.795 Test loss: 0.154  Test rocauc: 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.96it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: LR: 0.00002, Train loss: 0.153 Train rocauc: 0.974 Valid loss: 0.117  Valid rocauc: 0.782 Test loss: 0.163  Test rocauc: 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.01it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.92it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: LR: 0.00000, Train loss: 0.145 Train rocauc: 0.976 Valid loss: 0.120  Valid rocauc: 0.781 Test loss: 0.168  Test rocauc: 0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.02it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: LR: 0.00001, Train loss: 0.145 Train rocauc: 0.976 Valid loss: 0.122  Valid rocauc: 0.785 Test loss: 0.171  Test rocauc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.98it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: LR: 0.00004, Train loss: 0.142 Train rocauc: 0.977 Valid loss: 0.127  Valid rocauc: 0.790 Test loss: 0.177  Test rocauc: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.14it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: LR: 0.00010, Train loss: 0.147 Train rocauc: 0.975 Valid loss: 0.105  Valid rocauc: 0.801 Test loss: 0.157  Test rocauc: 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:00<00:00,  1.07it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.87it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: LR: 0.00016, Train loss: 0.147 Train rocauc: 0.976 Valid loss: 0.126  Valid rocauc: 0.771 Test loss: 0.182  Test rocauc: 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.93it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: LR: 0.00021, Train loss: 0.155 Train rocauc: 0.973 Valid loss: 0.130  Valid rocauc: 0.749 Test loss: 0.185  Test rocauc: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.01s/it]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: LR: 0.00026, Train loss: 0.160 Train rocauc: 0.971 Valid loss: 0.104  Valid rocauc: 0.800 Test loss: 0.155  Test rocauc: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:06<00:00,  1.02s/it]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.67it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: LR: 0.00029, Train loss: 0.162 Train rocauc: 0.970 Valid loss: 0.127  Valid rocauc: 0.800 Test loss: 0.195  Test rocauc: 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.05it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.03it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: LR: 0.00030, Train loss: 0.159 Train rocauc: 0.971 Valid loss: 0.099  Valid rocauc: 0.789 Test loss: 0.184  Test rocauc: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:58<00:00,  1.11it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.05it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: LR: 0.00028, Train loss: 0.153 Train rocauc: 0.974 Valid loss: 0.097  Valid rocauc: 0.811 Test loss: 0.163  Test rocauc: 0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.90it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: LR: 0.00024, Train loss: 0.141 Train rocauc: 0.977 Valid loss: 0.129  Valid rocauc: 0.813 Test loss: 0.194  Test rocauc: 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:02<00:00,  1.04it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  2.00it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: LR: 0.00019, Train loss: 0.134 Train rocauc: 0.980 Valid loss: 0.109  Valid rocauc: 0.814 Test loss: 0.184  Test rocauc: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:01<00:00,  1.06it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.97it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: LR: 0.00013, Train loss: 0.120 Train rocauc: 0.985 Valid loss: 0.124  Valid rocauc: 0.817 Test loss: 0.209  Test rocauc: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:03<00:00,  1.02it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.93it/s]\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: LR: 0.00007, Train loss: 0.100 Train rocauc: 0.989 Valid loss: 0.116  Valid rocauc: 0.795 Test loss: 0.207  Test rocauc: 0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 44/65 [00:42<00:20,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-272f25016c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for epoch in range(args.num_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    for num_iters, data in enumerate(tqdm(train_loader)):\n",
    "        data.to(args.device)\n",
    "        # strats = {'ea': data.edge_attr, 'sd': data.sd_edge_attr} # 'lap_x': data.lap_x\n",
    "        strats = {'ja': data.jaccard_edge_attr}\n",
    "        out = model(data.x, data.batch, data.edge_index, strats)\n",
    "        loss = criterion(out, data.y.float())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss += [loss.item()]\n",
    "        \n",
    "        y_true += [data.y]\n",
    "        y_scores += [out]\n",
    "        \n",
    "    args.writer.add_scalar(\"LR/epoch\", optimizer.param_groups[0]['lr'], epoch + 1)\n",
    "    args.writer.add_scalar(\"Loss/train\", np.average(train_loss), epoch + 1)\n",
    "    input_dict = {\"y_true\": torch.cat(y_true), \"y_pred\": torch.cat(y_scores)}\n",
    "    train_metric = evaluator.eval(input_dict)[args.metric]\n",
    "    args.writer.add_scalar(args.metric + \"/train\", train_metric, epoch + 1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = []\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        for num_iters, data in enumerate(tqdm(valid_loader)):\n",
    "            data.to(args.device)\n",
    "            # strats = {'ea': data.edge_attr, 'sd': data.sd_edge_attr} # 'lap_x': data.lap_x\n",
    "            strats = {'ja': data.jaccard_edge_attr}\n",
    "            out = model(data.x, data.batch, data.edge_index, strats)\n",
    "        \n",
    "            loss = criterion(out, data.y.float())\n",
    "            valid_loss += [loss.item()]\n",
    "\n",
    "            y_true += [data.y]\n",
    "            y_scores += [out]\n",
    "\n",
    "        input_dict = {\"y_true\": torch.cat(y_true), \"y_pred\": torch.cat(y_scores)}\n",
    "        valid_metric = evaluator.eval(input_dict)[args.metric]\n",
    "        args.writer.add_scalar(\"Loss/valid\", np.average(valid_loss), epoch + 1)\n",
    "        args.writer.add_scalar(args.metric + \"/valid\", valid_metric, epoch + 1)\n",
    "        \n",
    "        test_loss = []\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        for data in test_loader:\n",
    "            data.to(args.device)\n",
    "            # strats = {'ea': data.edge_attr, 'sd': data.sd_edge_attr} # 'lap_x': data.lap_x\n",
    "            strats = {'ja': data.jaccard_edge_attr}\n",
    "            out = model(data.x, data.batch, data.edge_index, strats)\n",
    "        \n",
    "            loss = criterion(out, data.y.float())\n",
    "            test_loss += [loss.item()]\n",
    "\n",
    "            y_true += [data.y]\n",
    "            y_scores += [out]\n",
    "\n",
    "        input_dict = {\"y_true\": torch.cat(y_true), \"y_pred\": torch.cat(y_scores)}\n",
    "        test_metric = evaluator.eval(input_dict)[args.metric]\n",
    "        args.writer.add_scalar(\"Loss/test\", np.average(test_loss), epoch + 1)\n",
    "        args.writer.add_scalar(args.metric + \"/test\", test_metric, epoch + 1)\n",
    "    \n",
    "    print('Epoch %d: LR: %.5f, Train loss: %.3f Train %s: %.3f Valid loss: %.3f  Valid %s: %.3f Test loss: %.3f  Test %s: %.3f' \\\n",
    "          % (epoch + 1, optimizer.param_groups[0]['lr'], np.average(train_loss), args.metric, train_metric, \\\n",
    "             np.average(valid_loss), args.metric, valid_metric, \\\n",
    "             np.average(test_loss), args.metric, test_metric))\n",
    "    stats += [[epoch, np.average(train_loss), train_metric, np.average(valid_loss), valid_metric, np.average(test_loss), test_metric]]\n",
    "\n",
    "args.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = ['epoch', 'train_loss', 'train_metric', 'valid_loss', 'valid_metric', 'test_loss', 'test_metric']\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "stats_np = np.array(stats)\n",
    "best_valid = stats_np[stats_np[:, 4].argmax()]\n",
    "print(best_valid)\n",
    "for i in range(1, stats_np.shape[-1]):\n",
    "    ax = fig.add_subplot(2, 3, i)\n",
    "    ax.plot(stats_np[:, i], label=labels[i])\n",
    "    ax.scatter(x=best_valid[0], y=best_valid[i], color='red')\n",
    "    ax.annotate(best_valid[i].round(3), xy=(best_valid[0]+5, best_valid[i]), color='red')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
